{"/api_reference":{"title":"API Reference","data":{"":"This reference documents every object and method available in Kaizenâ€™s SDK and API.For a step-by-step guide on how to use Kaizen, check out the Getting Started.","code-reviewer#Code Reviewer":"","class-codereviewer#Class: CodeReviewer":"","constructor#Constructor":"__init__(self, llm_provider: LLMProvider)\nInitializes the CodeReviewer with the provided LLM provider.","methods#Methods":"","review_pull_request#review_pull_request":"review_pull_request(self, diff_text: str, pull_request_title: str, pull_request_desc: str, pull_request_files: List[Dict], reeval_response: bool = False) -> ReviewData\nReviews a pull request and generates feedback.\nParameters:\ndiff_text: The diff text of the pull request.\npull_request_title: The title of the pull request.\npull_request_desc: The description of the pull request.\npull_request_files: List of files changed in the pull request.\nreeval_response: Whether to re-evaluate the response.\nReturns: ReviewData object containing the review results.","class-prdescriptiongenerator#Class: PRDescriptionGenerator":"","constructor-1#Constructor":"__init__(self, llm_provider: LLMProvider)\nInitializes the PRDescriptionGenerator with the provided LLM provider.","methods-1#Methods":"","generate_pull_request_desc#generate_pull_request_desc":"generate_pull_request_desc(self, diff_text: str, pull_request_title: str, pull_request_desc: str, pull_request_files: List[Dict], user: str) -> str\nGenerates a description for a pull request.\nParameters:\ndiff_text: The diff text of the pull request.\npull_request_title: The title of the pull request.\npull_request_desc: The existing description of the pull request.\npull_request_files: List of files changed in the pull request.\nuser: The user or context for generating the description.\nReturns: A string containing the generated pull request description.","unit-test-generator#Unit Test generator":"","class-unittestgenerator#Class: UnitTestGenerator":"","constructor-2#Constructor":"__init__(self, verbose=False)\nInitializes the UnitTestGenerator with optional verbosity setting.","methods-2#Methods":"","generate_tests_from_dir#generate_tests_from_dir":"generate_tests_from_dir(self, dir_path: str, output_path: str = None)\nGenerates unit tests for all supported files in a given directory.\nParameters:\ndir_path: Path of the directory containing source files.\nmax_critique: Maximum number of critique iterations.\noutput_path: (Optional) Custom output path for generated tests.\nverbose: Enable verbose logging.\nenable_critique: Enable AI critique and improvement of generated tests.\nReturns: A tuple containing an empty dictionary and llm usage statistics.","generate_tests#generate_tests":"generate_tests(self, file_path: str, content: str = None, max_critique: int = 3, output_path: str = None, verbose: bool = False, enable_critique: bool = False)\nGenerates unit tests for a given file with various configuration options.\nParameters:\nfile_path: Path of the file relative to the project root.\ncontent: (Optional) File content.\nmax_critique: Maximum number of critique iterations.\noutput_path: (Optional) Custom output path for generated tests.\nverbose: Enable verbose logging.\nenable_critique: Enable AI critique and improvement of generated tests.\nReturns: A tuple containing an empty dictionary and llm usage statistics.","run_tests#run_tests":"run_tests(self) -> Dict\nRuns the generated unit tests and returns the results.","code-scanner#Code Scanner":"","class-codescanner#Class: CodeScanner":"","constructor-3#Constructor":"__init__(self, llm_provider: LLMProvider)\nInitializes the CodeScanner with the provided LLM provider.","methods-3#Methods":"","review_code#review_code":"review_code(self, file_data: str, user: str) -> ReviewData\nPerforms a code review on a single file.\nParameters:\nfile_data: Content of the file to be reviewed.\nuser: Username or project identifier.\nReturns: ReviewData object containing the review results.","review_code_dir#review_code_dir":"review_code_dir(self, dir_path: str, reevaluate: bool = False, user: str) -> ReviewData\nPerforms a code review on all files in a directory.\nParameters:\ndir_path: Path to the directory containing the files to be reviewed.\nreevaluate: Whether to reevaluate previously scanned files.\nuser: Username or project identifier.\nReturns: ReviewData object containing the review results for all files.","ui-reviewer#UI Reviewer":"","class-uireviewer#Class: UIReviewer":"","constructor-4#Constructor":"__init__(self, llm_provider: LLMProvider):\nInitializes the UI Reviewer with the provided LLM provider.","methods-4#Methods":"","generate_ui_review#generate_ui_review":"generate_ui_review(self, url: str = None, html_content: str = None) -> Dict\nPerforms a UI review on a given URL or HTML code.\nParameters:\nurl: URL of the web page to be reviewed.\nhtml_code: HTML code to be reviewed.\nReturns: A dictionary containing the review results.","end-to-end-test-generator#End to End Test Generator":"","class-e2etestgenerator#Class: E2ETestGenerator":"","constructor-5#Constructor":"__init__(self)\nInitializes the E2ETestGenerator.","methods-5#Methods":"","generate_e2e_tests#generate_e2e_tests":"generate_e2e_tests(self, url: str) -> Tuple[List[Dict], Dict]\nGenerates E2E UI tests for the given URL.\nParameters:\nurl: URL of the web application to test.\nReturns: A tuple containing a list of generated tests and LLM usage statistics.","run_tests-1#run_tests":"run_tests(self) -> Dict\nRuns the generated E2E UI tests.\nReturns: A dictionary containing test execution results.","work-summary-generator#Work Summary Generator":"","class-worksummarygenerator#Class: WorkSummaryGenerator":"","constructor-6#Constructor":"__init__(self)\nInitializes the WorkSummaryGenerator.","methods-6#Methods":"","generate_work_summaries#generate_work_summaries":"generate_work_summaries(self, file_diffs: List[Dict], user: str) -> Dict\nGenerates a work summary from the provided file diffs.\nParameters:\nfile_diffs: List of dictionaries containing file diff information.\nuser: Username or identifier for the user generating the summary.\nReturns: A dictionary containing the generated summary and other relevant information.","generate_twitter_post#generate_twitter_post":"generate_twitter_post(self, summary: str, user: str) -> Tuple[str, Dict]\nGenerates a Twitter post based on the work summary.\nParameters:\nsummary: The generated work summary.\nuser: Username or identifier for the user generating the post.\nReturns: A tuple containing the generated Twitter post and LLM usage statistics.","generate_linkedin_post#generate_linkedin_post":"generate_linkedin_post(self, summary: str, user: str) -> Tuple[str, Dict]\nGenerates a LinkedIn post based on the work summary.\nParameters:\nsummary: The generated work summary.\nuser: Username or identifier for the user generating the post.\nReturns: A tuple containing the generated LinkedIn post and LLM usage statistics."}},"/cloud_platform":{"title":"Getting Started with Kaizen Cloud Platform","data":{"":"Welcome to the Kaizen Cloud Platform! This guide will help you set up and start using our AI-powered code review and testing services.","introduction-video#Introduction Video":"Before we dive into the setup process, watch this short introduction video to get an overview of the Kaizen Cloud Platform:","step-1-sign-up-for-an-account#Step 1: Sign Up for an Account":"Visit https://kaizen.cloudcode.ai\nClick on the \"Sign Up\" button in the top right corner\nFill out the registration form with your details\nVerify your email address by clicking the link sent to your inbox","step-2-create-a-new-project#Step 2: Create a New Project":"Once you're logged in:\nClick on the \"New Project\" button on your dashboard\nChoose a name for your project\nSelect the repository you want to connect (GitHub, GitLab, or Bitbucket)\nFollow the prompts to authorize Kaizen to access your repository","step-3-configure-kaizen-bot#Step 3: Configure Kaizen bot":"Install the kaizen bot by going to this link: \nCheck the permission which kaizen bot requires.\nSelect repositories you want to install kaizen bot.","next-steps#Next Steps":"Kaizen bot should start working whenever you create a PR.Need help? Don't hesitate to contact our support team or join our community Discord for assistance."}},"/configuration":{"title":"Configuration Guide","data":{"":"This document explains the structure and options available in the config.json file, which is used to configure our project.","overview#Overview":"The config.json file is divided into two main sections:\nlanguage_model: Configures the AI language model settings.\ngithub_app: Configures the GitHub app integration settings.\nYou need to store this in the root folder from where you call the kaizen module.","language-model-configuration#Language Model Configuration":"The language_model section contains the following fields:","general-settings#General Settings":"provider: Specifies the provider for the language model (e.g., \"litellm\").\nenable_observability_logging: Boolean flag to enable or disable observability logging.\nredis_enabled: Boolean flag to enable or disable Redis. Used for load balancing multiple models.\nSample Config config.json:\n{\n    \"language_model\": {\n        \"provider\": \"litellm\",\n        \"enable_observability_logging\": true,\n        \"redis_enabled\": true,\n        \"models\": [\n            {\n                \"model_name\": \"default\",\n                \"litellm_params\": {\n                    \"model\": \"gpt-3.5-turbo-1106\",\n                    \"input_cost_per_token\": 0.0000005,\n                    \"output_cost_per_token\": 0.0000015\n                }\n            },\n            {\n                \"model_name\": \"best\",\n                \"litellm_params\": {\n                    \"model\": \"gpt-4o\",\n                    \"input_cost_per_token\": 0.000005,\n                    \"output_cost_per_token\": 0.000015\n                }\n            },\n            {\n                \"model_name\": \"CUSTOM_MODEL\",\n                \"litellm_params\": {\n                    \"model\": \"azure_ai/MODEL_NAME\",\n                    \"api_key\": \"os.environ/CUSTOM_API_KEY\",\n                    \"api_base\": \"os.environ/CUSTOM_API_BASE\"\n                },\n                \"model_info\": {\n                    \"max_tokens\": 4096,\n                    \"input_cost_per_token\": 0.000015,\n                    \"output_cost_per_token\": 0.000015,\n                    \"max_input_tokens\": 128000,\n                    \"max_output_tokens\": 4096,\n                    \"litellm_provider\": \"openai\",\n                    \"mode\": \"chat\"\n                }\n            }\n        ]\n    },\n    \"github_app\": {\n        \"check_signature\": false,\n        \"auto_pr_review\": true,\n        \"edit_pr_desc\": true,\n        \"process_on_push\": true,\n        \"auto_unit_test_generation\": false\n    }\n}","models#Models":"The models array contains configurations for various language models. Each model configuration has the following structure:\n{\n  \"model_name\": \"string\",\n  \"litellm_params\": {\n    \"model\": \"string\",\n    \"input_cost_per_token\": number,\n    \"output_cost_per_token\": number\n  },\n  \"model_info\": { // Optional\n    // Additional model information\n  }\n}\nKey components:\nmodel_name: A custom identifier you assign to the model. You can have multiple configurations with the same model_name, which is useful for routing purposes.\nlitellm_params.model: The official model identifier used by the provider. For example, Azure's GPT-4 might be referenced as azure/gpt-4o.\nlitellm_params.input_cost_per_token and litellm_params.output_cost_per_token: Specify the cost per token for input and output respectively.\nmodel_info: An optional object for additional model-specific information.\nThis flexible structure allows you to define and manage multiple model configurations, including different versions or providers for the same model type.","default-model#Default Model":"{\n  \"model_name\": \"default\",\n  \"litellm_params\": {\n    \"model\": \"gpt-3.5-turbo-1106\",\n    \"input_cost_per_token\": 0.0000005,\n    \"output_cost_per_token\": 0.0000015\n  }\n}\nThis configuration sets up the default model, which is a GPT-3.5 Turbo variant.","best-model#Best Model":"{\n  \"model_name\": \"best\",\n  \"litellm_params\": {\n    \"model\": \"gpt-4o\",\n    \"input_cost_per_token\": 0.000005,\n    \"output_cost_per_token\": 0.000015\n  }\n}\nThis configuration sets up the \"best\" model, which is a GPT-4 variant.","custom-model#Custom Model":"{\n  \"model_name\": \"CUSTOM_MODEL\",\n  \"litellm_params\": {\n    \"model\": \"azure_ai/MODEL_NAME\",\n    \"api_key\": \"os.environ/CUSTOM_API_KEY\",\n    \"api_base\": \"os.environ/CUSTOM_API_BASE\"\n  },\n  \"model_info\": {\n    \"max_tokens\": 4096,\n    \"input_cost_per_token\": 0.000015,\n    \"output_cost_per_token\": 0.000015,\n    \"max_input_tokens\": 128000,\n    \"max_output_tokens\": 4096,\n    \"litellm_provider\": \"openai\",\n    \"mode\": \"chat\"\n  }\n}\nThis configuration sets up a custom model. The CUSTOM_API_KEY and CUSTOM_API_BASE are retrieved from environment variables.","github-app-configuration#GitHub App Configuration":"The github_app section configures the behavior of the GitHub app integration:\n{\n  \"check_signature\": false,\n  \"auto_pr_review\": true,\n  \"edit_pr_desc\": true,\n  \"process_on_push\": true,\n  \"auto_unit_test_generation\": false\n}\ncheck_signature: Boolean flag to enable or disable signature checking.\nauto_pr_review: Boolean flag to enable or disable automatic PR reviews.\nedit_pr_desc: Boolean flag to allow editing of PR descriptions.\nprocess_on_push: Boolean flag to enable processing on push events.\nauto_unit_test_generation: Boolean flag to enable automatic unit test generation.","customizing-the-configuration#Customizing the Configuration":"To customize the configuration:\nCopy the config.json file to your project root.\nModify the values according to your needs.\nEnsure that any referenced environment variables (e.g., CUSTOM_API_KEY) are properly set in your environment.\nRemember to restart your application after making changes to the configuration file for the changes to take effect."}},"/contact_us":{"title":"Contact Us","data":{"":"If you have any questions or need further assistance, please feel free to contact us at support@cloudcode.ai.You can also schedule a demo call here, or connect with any founder on their social media:Demo Call: https://cloudcode.ai/book-a-demo.htmlSaurav Panda\nhttps://github.com/sauravpanda\nhttps://www.linkedin.com/in/pandasaurav/Shreyash Gupta\nhttps://github.com/shreyashkgupta\nhttps://www.linkedin.com/in/shreyashkgupta/"}},"/contributing/code_of_conduct":{"title":"Code of Conduct","data":{"our-pledge#Our Pledge":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","our-standards#Our Standards":"Examples of behavior that contributes to creating a positive environment include:\nUsing welcoming and inclusive language\nBeing respectful of differing viewpoints and experiences\nGracefully accepting constructive criticism\nFocusing on what is best for the community\nShowing empathy towards other community members\nExamples of unacceptable behavior by participants include:\nThe use of sexualized language or imagery and unwelcome sexual attention or advances\nTrolling, insulting/derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others' private information, such as a physical or electronic address, without explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting","enforcement#Enforcement":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at oss@cloudcode.ai . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately."}},"/contributing/development_setup":{"title":"Kaizen Development Setup Guide","data":{"":"This guide will walk you through the process of setting up the Kaizen development environment.","step-1-clone-the-repository#Step 1: Clone the Repository":"First, clone the Kaizen repository from GitHub:\ngit clone https://github.com/your-username/kaizen.git\ncd kaizen","step-2-set-up-environment-variables#Step 2: Set Up Environment Variables":"Copy the .env.example file to create a new .env file:\ncp .env.example .env\nMake sure to fill in the necessary environment variables in the .env file.","step-3-configure-configjson#Step 3: Configure config.json":"Create a config.json file in the root directory of the project. The general structure should look like this:\n{\n    \"language_model\": {\n        \"provider\": \"litellm\",\n        \"enable_observability_logging\": true,\n        \"redis_enabled\": true,\n        \"models\": [\n            {\n                \"model_name\": \"default\",\n                \"litellm_params\": {\n                    \"model\": \"gpt-4o-mini\",\n                    \"input_cost_per_token\": 0.000000015,\n                    \"output_cost_per_token\": 0.0000006\n                }\n            },\n            {\n                \"model_name\": \"best\",\n                \"litellm_params\": {\n                    \"model\": \"gpt-4o\",\n                    \"input_cost_per_token\": 0.000005,\n                    \"output_cost_per_token\": 0.000015\n                }\n            },\n            {\n                \"model_name\": \"CUSTOM_MODEL\",\n                \"litellm_params\": {\n                    \"model\": \"azure_ai/MODEL_NAME\",\n                    \"api_key\": \"os.environ/CUSTOM_API_KEY\",\n                    \"api_base\": \"os.environ/CUSTOM_API_BASE\"\n                },\n                \"model_info\": {\n                    \"max_tokens\": 4096,\n                    \"input_cost_per_token\": 0.000015,\n                    \"output_cost_per_token\": 0.000015,\n                    \"max_input_tokens\": 128000,\n                    \"max_output_tokens\": 4096,\n                    \"litellm_provider\": \"openai\",\n                    \"mode\": \"chat\"\n                }\n            }\n        ]\n    },\n    \"github_app\": {\n        \"check_signature\": false,\n        \"auto_pr_review\": true,\n        \"edit_pr_desc\": true,\n        \"process_on_push\": true,\n        \"auto_unit_test_generation\": false\n    }\n}","configuration-notes#Configuration Notes:":"model_name is the type of model used for routing. You can have multiple models with the same model_name.\nlitellm_params.model is the actual model name by provider. Refer to the LiteLLM documentation for more details.\nAll API keys should be set up in the .env file.\nYou can set up custom models with custom API keys and base names.","step-4-running-examples#Step 4: Running Examples":"Once the setup is complete, you can run any example using the following command:\nPYTHONPATH=. poetry run python examples/basic/generate.py","development-and-testing#Development and Testing":"To test any development changes:\nFeel free to update the examples as they use the local Kaizen files.\nCreate your own tests in the tests directory.","additional-resources#Additional Resources":"LiteLLM Documentation\nKaizen GitHub Repository\nFor more information or if you encounter any issues, please refer to the project's documentation or create an issue on the GitHub repository."}},"/contributing/how_to_contribute":{"title":"How to Contribute to Our Open Source Project","data":{"":"We're excited that you're interested in contributing to our project! This guide will help you get started with contributing to Kaizen.","table-of-contents#Table of Contents":"Getting Started\nSetting Up Your Development Environment\nFinding Issues to Work On\nMaking Changes\nSubmitting a Pull Request\nCode Review Process\nCommunity Guidelines","getting-started#Getting Started":"Fork the Repository: Start by forking our repository to your GitHub account.\nClone Your Fork: Clone your fork to your local machine:\ngit clone https://github.com/your-username/project-name.git\ncd project-name\nAdd Upstream Remote: Add the original repository as an upstream remote:\ngit remote add upstream https://github.com/Cloud-Code-AI/kaizen.git","setting-up-your-development-environment#Setting Up Your Development Environment":"Install Dependencies: Follow the instructions in our README.md to install necessary dependencies.\npoetry install\nCreate a Branch: Create a new branch for your work:\ngit checkout -b feature/your-feature-name","finding-issues-to-work-on#Finding Issues to Work On":"Check our Issues page for open issues.\nLook for issues tagged with good first issue or help wanted.\nIf you have an idea for a new feature, open an issue to discuss it before starting work.","making-changes#Making Changes":"Write Your Code: Make your changes, following our coding standards and guidelines.\nWrite Tests: Add or update tests as necessary.\nRun Tests: Ensure all tests pass:\npytest .\nCommit Your Changes: Use clear and concise commit messages:\ngit commit -m \"Add feature: brief description of changes\"","submitting-a-pull-request#Submitting a Pull Request":"Push Your Changes: Push your branch to your fork:\ngit push origin feature/your-feature-name\nOpen a Pull Request: Go to the original repository on GitHub and open a pull request.\nDescribe Your Changes: In the PR description, explain your changes and link to any relevant issues.","code-review-process#Code Review Process":"Maintainers will review your PR and may request changes.\nAddress any comments or requested changes.\nOnce approved, a maintainer will merge your PR.","community-guidelines#Community Guidelines":"Be respectful and inclusive in your interactions with other contributors.\nFollow our Code of Conduct.\nParticipate in discussions and help other contributors.","additional-resources#Additional Resources":"Project Documentation\nCoding Standards\nJoin Our Community Chat\nThank you for contributing to our project! Your efforts help make our software better for everyone."}},"/contributing/overview":{"title":"Contributing to Our Project","data":{"":"We're thrilled that you're interested in contributing to our project! This section will guide you through the process of making contributions.","table-of-contents#Table of Contents":"Code of Conduct\nHow to Contribute\nDevelopment Setup\nPull Request Process\nStyle Guide\nWe welcome contributions of all kinds, from bug fixes to new features. Every contribution, no matter how small, is valuable and appreciated.Please take a moment to review this document to make the contribution process easy and effective for everyone involved."}},"/contributing/pull_request_process":{"title":"Pull Request Process","data":{"":"This document outlines the process for submitting a pull request to our project.","before-submitting-a-pull-request#Before Submitting a Pull Request":"Ensure any install or build dependencies are removed before the end of the layer when doing a build.\nUpdate the README.md with details of changes to the interface, this includes new environment variables, exposed ports, useful file locations and container parameters.\nIncrease the version numbers in any examples files and the README.md to the new version that this Pull Request would represent.","submitting-a-pull-request#Submitting a Pull Request":"Fork the repository and create your branch from main.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes.\nMake sure your code lints.\nIssue that pull request!\nOptionally add your social so that we can tag you when we share an update.","after-submitting-a-pull-request#After Submitting a Pull Request":"The maintainers will review your PR within a few days.\nThey may ask for changes or improvements.\nOnce approved, your PR will be merged into the main branch.\nRemember, the better you describe your pull request and the changes it introduces, the easier it will be for maintainers to review and merge it."}},"/contributing/setting_various_llms":{"title":"Setting up Language Models in config.json","data":{"":"To use various Language Models (LLMs) in your project, you need to configure them in the config.json file. This file should be located in the root directory of your project. Here's how you can set up different LLMs in the config.json file.","basic-setup#Basic Setup":"The config.json file should have the following structure:\n{\n    \"language_model\": {\n        \"provider\": \"litellm\",\n        \"enable_observability_logging\": true,\n        \"redis_enabled\": true,\n        \"models\": [\n            // Model configurations go here\n        ]\n    },\n    \"github_app\": {\n        \"check_signature\": false,\n        \"auto_pr_review\": true,\n        \"edit_pr_desc\": true,\n        \"process_on_push\": true,\n        \"auto_unit_test_generation\": false\n    }\n}\nThe language_model object contains the configurations for the LLMs you want to use. The models array inside it is where you define the configurations for each LLM.","example-open-ai-models#Example: Open AI models":"First, you need to add OPENAI_API_KEY in the .env file.\nHere's an example of how to configure a LitELLM model:\n{\n    \"model_name\": \"default\",\n    \"litellm_params\": {\n        \"model\": \"gpt-4o-mini\",\n        \"input_cost_per_token\": 0.000000015,\n        \"output_cost_per_token\": 0.0000006\n    }\n}\nIn this example, we're defining a model named default that uses the gpt-4o-mini model from LitELLM. The litellm_params object specifies the cost per token for input and output.","example-azure-openai-model#Example: Azure OpenAI Model":"For this example, you need to add the AZURE_API_BASE and AZURE_API_KEY in the .env file.\nTo configure an Azure OpenAI model, you can use the following structure:\n{\n    \"model_name\": \"CUSTOM_MODEL\",\n    \"litellm_params\": {\n        \"model\": \"azure_ai/MODEL_NAME\",\n        \"api_key\": \"os.environ['AZURE_API_KEY']\",\n        \"api_base\": \"os.environ['AZURE_API_BASE']\"\n    },\n    \"model_info\": {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\": 0.000015,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\"\n    }\n}","example-groq-models#Example: Groq models":"For GroQ, you need to add the GROQ_API_KEY in the .env file.\nTo configure a GroQ model, you can use the following structure:\n{\n    \"model_name\": \"default\",\n    \"litellm_params\": {\n        \"model\": \"groq/llama3-8b-8192\"\n    }\n}"}},"/contributing/style_guide":{"title":"Style Guide","data":{"":"To ensure consistency across the project, we follow these style guidelines:","code-style#Code Style":"We use Prettier for code formatting. Please ensure your code is formatted before submitting a PR.\nWe follow the Airbnb JavaScript Style Guide for JavaScript code.","commit-messages#Commit Messages":"We use the Conventional Commits specification for commit messages:\nfeat: for new features\nfix: for bug fixes\ndocs: for documentation changes\nstyle: for changes that do not affect the meaning of the code\nrefactor: for code changes that neither fix a bug nor add a feature\nperf: for code changes that improve performance\ntest: for adding or modifying tests\nchore: for changes to the build process or auxiliary tools","documentation-style#Documentation Style":"Use MDX for documentation files.\nKeep language clear and concise.\nUse code blocks for examples.\nInclude links to relevant sections or external resources.","cssscss#CSS/SCSS":"Use kebab-case for class names (e.g., .my-class-name).\nAvoid using IDs for styling.\nUse variables for colors, fonts, and other repeated values.\nRemember, these guidelines are here to help maintain consistency, but they're not set in stone. If you have a good reason to deviate from them, please explain in your pull request."}},"/feature_request":{"title":"Feature Requests","data":{"":"We welcome feature requests from our users, as they help us improve our product and provide a better experience for everyone. If you have an idea for a new feature or an improvement to an existing one, please follow the steps below to submit a feature request.","check-existing-requests#Check Existing Requests":"Before creating a new feature request, we recommend checking the existing ones in our GitHub Discussions to see if your idea has already been suggested. If you find a similar request, you can upvote it or add your thoughts to the existing discussion.","create-a-new-discussion#Create a New Discussion":"If your feature request is unique, you can create a new discussion by following these steps:\nGo to the GitHub Discussions page for our repository.\nClick on the \"New Discussion\" button.\nSelect the \"Feature Request\" category from the dropdown menu.\nProvide a clear and descriptive title for your feature request.\nIn the discussion body, provide a detailed description of your proposed feature or enhancement. Include the following information:\nA brief overview of the feature\nThe problem it solves or the benefit it provides\nAny relevant use cases or scenarios\nMockups, diagrams, or examples (if applicable)\nAny additional context or information that could be helpful","engage-with-the-community#Engage with the Community":"Once you've created your feature request, others in the community can view, comment, and react to it. We encourage you to engage with the community, answer questions, and provide additional details or clarifications as needed.","wait-for-review-and-feedback#Wait for Review and Feedback":"Our team regularly reviews the feature requests in the discussions. We may ask for additional information, provide feedback, or share our plans regarding the implementation of the feature. Please be patient, as we carefully evaluate each request and prioritize them based on various factors.","stay-informed#Stay Informed":"We will update the discussion with any progress or decisions made regarding your feature request. If your request is accepted for implementation, we will provide updates on the development timeline and release plans.Thank you for your contributions and for helping us make our product better!"}},"/features/code_review":{"title":"Code Review","data":{"code-reviewer#Code Reviewer":"Automatically get reviews and feedback on code changes in your pull requests on GitHub.\nStreamline code reviews and ensure high code quality commit messages across your codebase.","key-features#Key Features":"Automated Code Analysis: Analyzes code changes in pull requests and generates detailed feedback.\nOrganized Feedback: Provides review comments organized by topics and confidence levels.\nInteractive Reviews: Allows engagement with the bot for clarification or additional context.\nPR Description Generation: Automatically generates descriptive summaries of code changes.\nContinuous Learning: Improves review quality over time based on user interactions.","how-it-works#How it Works":"Diff Analysis: When you create or update a pull request, the Kaizen Bot analyzes the code changes (diff) and generates detailed feedback based on the modified code snippets.\nOrganized Feedback: The bot's feedback is organized into topics or categories like performance, security, code style, or documentation, making it easier to navigate and prioritize the comments.\nConfidence Levels: Each review comment includes a confidence level (critical, high, medium, low), indicating the perceived importance or severity of the issue.\nContextual Information: The reviews provide context-specific details like file names, line numbers, code snippets, and explanations for the suggested changes.\nPR Description Generation: The bot can generate a descriptive summary of the code changes, helping you better document your pull requests.\nYou can find an example here","usage-guide#Usage Guide":"Getting Started: For a quickstart you can use the cloud hosted web application that we provide by following this. You can also choose to self host the Kaizen Github Bot locally by following the advanced guide here.\nThe next given steps explore the latter approach in details.\nCreate or Update a Pull Request: The Kaizen Bot will automatically analyze the code changes and generate a review.\nReview the Feedback: The bot's feedback will be shared as a comment on your pull request, organized by topics and confidence levels.\nEngage with the Bot: You can interact with the bot, provide additional context, or request clarification on its feedback.\nIterate and Improve: As you work with the bot, it will learn from your responses and improve the quality of its reviews over time.","example#Example":"Here's a complete example to review a pull request:\nfrom kaizen.reviewer.code_review import CodeReviewer\nfrom kaizen.generator.pr_description import PRDescriptionGenerator\nfrom kaizen.llms.provider import LLMProvider\nfrom github_app.github_helper.utils import get_diff_text, get_pr_files\nfrom github_app.github_helper.pull_requests import clean_keys, create_review_comments\nfrom kaizen.formatters.code_review_formatter import create_pr_review_text\nimport json\nimport logging\nlogging.basicConfig(level=\"DEBUG\")\n# Pull request information\npr_diff = \"https://github.com/Cloud-Code-AI/kaizen/pull/335.patch\"\npr_files = \"https://api.github.com/repos/Cloud-Code-AI/kaizen/pulls/335/files\"\npr_title = \"feat: updated the prompt to provide solution\"\n# Get diff text and PR files\ndiff_text = get_diff_text(pr_diff, \"\")\npr_files = get_pr_files(pr_files, \"\")\n# Create CodeReviewer instance\nreviewer = CodeReviewer(llm_provider=LLMProvider())\n# Review pull request\nreview_data = reviewer.review_pull_request(\n    diff_text=diff_text,\n    pull_request_title=pr_title,\n    pull_request_desc=\"\",\n    pull_request_files=pr_files,\n    reeval_response=False,\n)\n# Process review data\ntopics = clean_keys(review_data.topics, \"important\")\nreview_desc = create_pr_review_text(\n    review_data.issues, code_quality=review_data.code_quality\n)\ncomments, topics = create_review_comments(topics)\n# Display results\nprint(f\"Raw Topics:\\n{json.dumps(topics, indent=2)}\\n\")\nprint(f\"GENERATED REVIEW:\\n{review_desc}\")\nprint(f\"\\nComment and topics:\\n{json.dumps(comments, indent=2)},\\n{topics}\")\n# Generate PR description\nprint(\"---------------Generate desc-------------\")\npr_desc = PRDescriptionGenerator(llm_provider=LLMProvider())\ndesc_data = pr_desc.generate_pull_request_desc(\n    diff_text=None,\n    pull_request_title=pr_title,\n    pull_request_desc=\"\",\n    pull_request_files=pr_files,\n    user=\"kaizen/example\",\n)\nprint(desc_data)","supported-input#Supported Input":"GitHub pull request information (diff, files, title, description)","benefits#Benefits":"Improved Code Quality\nTime Savings\nConsistent Standards\nKnowledge Sharing\nAutomated Documentation","limitations#Limitations":"AI Limitations: While advanced, the bot may still have limitations in understanding complex code or context-specific nuances.\nHuman Oversight: The bot's feedback should be considered a complementary tool to human code reviews, not a complete replacement.\nGitHub API Limitations: Rate limits and authentication requirements may affect large-scale usage."}},"/features/code_scan":{"title":"Code Scan","data":{"code-scanner#Code Scanner":"Comprehensive static code analysis to identify potential issues, vulnerabilities, and areas for improvement in your codebase.","key-features#Key Features":"Static Analysis: The feature performs in-depth analysis of your code to identify potential issues, vulnerabilities, and areas for improvement.\nMulti-language Support: Code Scanner can analyze code in various programming languages and frameworks.\nDetailed Reporting: Generates comprehensive reports highlighting issues, potential bugs, and suggestions for improvement.\nSecurity Vulnerability Detection: Identifies potential security vulnerabilities in the codebase.\nCode Quality Metrics: Provides metrics and insights on code quality and maintainability.","how-it-works#How it Works":"Input your source code or provide access to your repository.\nThe Code Scanner employs advanced algorithms and AI to analyze the code and generate a detailed report of findings.\nThe scanner identifies potential issues, vulnerabilities, and areas for improvement in your codebase.\nYou can find an example here","usage-guide#Usage Guide":"Here's a detailed step-by-step guide on how to use the Code Scanner:\nFollow the initial setup guide here.\nCreate a new Python file and import the necessary modules from Kaizen:\n from kaizen.reviewer.code_scan import CodeScanner\n from kaizen.llms.provider import LLMProvider\n import json\nCreate an instance of the CodeScanner:\nreviewer = CodeScanner(llm_provider=LLMProvider())\nProvide the source code file or directory path which you want to scan:You can scan a single file at a time:\n filename = \"path/to/your/file.py\"\n with open(filename, \"r+\") as f:\n     file_data = f.read()\n review_data = reviewer.review_code(file_data=file_data, user=\"YourUsername/ProjectName\")\nOr a whole directory:\n dir_path = \"path/to/your/directory/\"\n review_data = reviewer.review_code_dir(\n     dir_path=dir_path, reevaluate=True, user=\"YourUsername/ProjectName\"\n )\nDisplay the test results:\n print(f\"Total {len(review_data.issues)} Issues found!!!!\")\n print(json.dumps(review_data.issues, indent=2))\nReview the generated report and address the identified issues in your code.","example#Example":"Here's a complete example to generate unit tests for a specific file:\n    from kaizen.reviewer.code_scan import CodeScanner\n    from kaizen.llms.provider import LLMProvider\n    import json\n    # Create an instance of the CodeScanner\n    reviewer = CodeScanner(llm_provider=LLMProvider())\n    # Scan a single file\n    filename = \"github_app/main.py\"\n    with open(filename, \"r+\") as f:\n        file_data = f.read()\n    review_data = reviewer.review_code(file_data=file_data, user=\"Example/CodeScan\")\n    # Scan a whole directory\n    dir_path = \"github_app/\"\n    review_data = reviewer.review_code_dir(\n        dir_path=dir_path, reevaluate=True, user=\"Example/CodeScan\"\n    )\n    # Display the results\n    print(f\"Total {len(review_data.issues)} Issues found!!!!\")\n    print(json.dumps(review_data.issues, indent=2))","supported-languages#Supported Languages":"All programming languages","benefits#Benefits":"Early Bug Detection\nSecurity Vulnerability Identification\nCode Quality Improvement\nCoding Standard Enforcement\nTechnical Debt Reduction","limitations#Limitations":"False Positives: Some identified issues may not be actual problems in certain contexts.\nLanguage Coverage: Effectiveness may vary depending on programming language and framework.\nAI Limitations: May not catch all possible issues or understand complex project-specific requirements."}},"/features/e2e_testing":{"title":"E2e Testing","data":{"e2e-ui-test-generator#E2E UI Test Generator":"Streamline the process of creating and maintaining comprehensive end-to-end tests for web applications using the Playwright testing framework.\nGenerate robust and maintainable test scripts that can be seamlessly integrated into a CI/CD pipeline.","key-features#Key Features":"Test Plan Generation: The feature analyzes the application requirements or specifications and automatically generates a comprehensive test plan, covering various user flows and scenarios.\nPlaywright Test Script Generation: Based on the test plan, the feature generates Playwright test scripts written in Python 3.9, following best practices and industry standards.\nPage Object Model: The generated scripts implement the Page Object Model (POM) design pattern, promoting code reusability, maintainability, and separation of concerns.\nWeb Element Interaction: The scripts leverage Playwright's powerful features for interacting with web elements, such as clicking buttons, filling out forms, and navigating between pages.\nVisual Testing: The feature utilizes Playwright's capabilities to capture screenshots and videos during test execution, enabling visual validation and debugging.","how-it-works#How it Works":"Provide the URL of the web application you want to test.\nThe E2E UI Test Generator analyzes the web application's content and structure.\nIt generates comprehensive Playwright test scripts covering various UI modules and user flows.\nThe generated scripts can be executed locally or integrated into a CI/CD pipeline.\nYou can find an example here","usage-guide#Usage Guide":"Here's a detailed step-by-step guide on how to use the E2E UI Test Generator:\nFollow the initial setup guide here.\nCreate a new Python file and import the E2ETestGenerator module:\nfrom kaizen.generator.e2e_tests import E2ETestGenerator\nCreate an instance of the E2ETestGenerator:\ngenerator = E2ETestGenerator()\nGenerate E2E tests for a specific URL:\nWEBPAGE_URL = \"https://example.com\"\ntests, * = generator.generate_e2e_tests(WEBPAGE_URL)\nDisplay the generated tests:\nfor test in tests:\n    print(f'Module Title: {test[\"module_title\"]} || Importance: {test[\"importance\"]}')\n    for t in test[\"tests\"]:\n        print(f'Description: {t[\"test_description\"]}')\n        print(f'Code: \\n{t[\"code\"]}')\n        print(\"-----------------------------------------------------------\")\nRun the generated tests:\nresults = generator.run_tests()\nprint(f\"Test Execution results: \\n {results}\")\nReview the generated tests and execution results, and integrate them into your development workflow.","example#Example":"Here's a complete example to generate and run E2E UI tests:\nfrom kaizen.generator.e2e_tests import E2ETestGenerator\nimport time\nimport sys\nimport traceback\n# Create an instance of the E2E Test Generator\ngenerator = E2ETestGenerator()\n# Set the webpage URL to test\nWEBPAGE_URL = \"https://cloudcode.ai\"\nprint(f\"Generating UI tests for `{WEBPAGE_URL}`, please wait...\")\nstart_time = time.time()\ntry:\n    # Generate E2E tests\n    tests, * = generator.generate_e2e_tests(WEBPAGE_URL)\nexcept Exception as e:\n    print(f\"Error: {e}\")\n    print(traceback.format_exc())\n    sys.exit(1)\nend_time = time.time()\nelapsed_time = end_time - start_time\nprint(f\"\\nUI tests generated in {elapsed_time:.2f} seconds.\")\n# Display generated tests\nfor test in tests:\n    print(\n        f'#### ======== Module Title: {test[\"module_title\"]} || Importance: {test[\"importance\"]} ========== ####'\n    )\n    for t in test[\"tests\"]:\n        print(f'Desc: {t[\"test_description\"]}')\n        print(f'Code: \\n{t[\"code\"]}')\n        print(\"-----------------------------------------------------------\")\n# Run the generated tests\nresults = generator.run_tests()\nprint(f\"Test Execution results: \\n {results}\")\nTo execute the generated tests:\nimport pytest\nif __name__ == \"__main__\":\n    test_dir = \".kaizen/tests\"\n    pytest.main(\n        [\n            \"--timeout=60\",\n            \"-v\",\n            test_dir,\n        ]\n    )","supported-frameworks#Supported Frameworks":"Playwright","benefits#Benefits":"Accelerated Test Development\nImproved Test Coverage\nMaintainability and Reusability\nContinuous Quality Assurance\nVisual Validation\nScalability","limitations#Limitations":"Dynamic Content: May have limitations with highly dynamic or JavaScript-heavy applications.\nComplex Interactions: Advanced user interactions might require manual scripting.\nTest Data Management: Might need additional setup for managing test data across different environments."}},"/features/ui_review":{"title":"UI Review","data":{"ui-reviewer#UI Reviewer":"AI-powered analysis and feedback for improving user experience and accessibility of UI components.","key-features#Key Features":"UI Component Analysis: The feature analyzes HTML code of UI components to identify areas for improvement.\nUX Feedback: Provides actionable feedback to enhance user experience.\nAccessibility Evaluation: Identifies accessibility issues and suggests improvements for better compliance.\nOrganized Reporting: Generates feedback in a structured JSON format for easy interpretation and implementation.\nContinuous Improvement: Supports iterative development by providing ongoing feedback as UI evolves.","how-it-works#How it Works":"Input your HTML code or URL for which you want to generate UI reviews.\nThe UI Reviewer leverages advanced language models to analyze the code and generate a detailed report of findings.\nThe scanner identifies potential issues, accessibility issues, and areas for improvement in your UI.\nYou can find an example here","usage-guide#Usage Guide":"Here's a detailed step-by-step guide on how to use the UI Reviewer:\nFollow the initial setup guide here.\nCreate a new Python file and import the necessary modules from Kaizen:\n from kaizen.reviewer.ui_review import UIReviewer\n import json\nCreate an instance of the UI Reviewer:\nui_review = UIReviewer()\nProvide the URL or HTML code for which you want to generate UI reviews:UI review for a specific URL:\n url = \"https://cloudcode.ai\"\n reviews = ui_review.generate_ui_review(url=url)[\"reviews\"]\nUI review for HTML code:\n html_code = \"\"\"\n <div class=\"container\">\n     <h1>Welcome to CloudCode.ai</h1>\n     <p>This is a sample HTML code for UI review.</p>\n </div>\n \"\"\"\n reviews = ui_review.generate_ui_review(html_code=html_code)[\"reviews\"]\nDisplay the test results:\n print_block = \"\"\"\n -----------------------------------------------\n Topic: {topic}\n Review: {review}\n Confidence: {confidence}\n Solution: {solution}\n Code Block:\n ```html\n {code_block}\n ```\\n\\n\n \"\"\"\n for review in reviews:\n     content = print_block.format(\n         topic=review[\"topic\"],\n         review=review[\"comment\"],\n         confidence=review[\"confidence\"],\n         code_block=review[\"code_block\"],\n         solution=review[\"solution\"],\n     )\n     print(content)\nReview the generated report and address the identified issues in your code.","example#Example":"Here's a complete example to review the UI of a specific URL:\nfrom kaizen.reviewer.ui_review import UIReviewer\n# Create an instance of the UI Reviewer\nui_review = UIReviewer()\n# Generate UI review for a specific URL\nurl = \"https://cloudcode.ai\"\nreviews = ui_review.generate_ui_review(url=url)[\"reviews\"]\n# Display the results\nprint_block = \"\"\"\n-----------------------------------------------\nTopic: {topic}\nReview: {review}\nConfidence: {confidence}\nSolution: {solution}\nCode Block:\n```html\n{code_block}\n```\\n\\n\n\"\"\"\nfor review in reviews:\n    content = print_block.format(\n        topic=review[\"topic\"],\n        review=review[\"comment\"],\n        confidence=review[\"confidence\"],\n        code_block=review[\"code_block\"],\n        solution=review[\"solution\"],\n    )\n    print(content)","supported-input#Supported Input":"HTML code\nURLs of web pages","benefits#Benefits":"Improved User Experience\nAccessibility Compliance\nContinuous Improvement","limitations#Limitations":"AI Limitations: Understanding complex UI patterns or context-specific nuances.\nHuman Oversight: AI feedback should complement human review and testing."}},"/features/unit_test":{"title":"Unit Test","data":{"unit-test-generator#Unit Test Generator":"Automatically create comprehensive unit tests for your code, improving code quality and test coverage.","key-features#Key Features":"Unit Test Generation: The feature analyzes the code changes and generates comprehensive unit tests, covering various scenarios and edge cases.\nTest Coverage: The generated tests cover a wide range of scenarios, including edge cases, boundary conditions, and exception handling.\nTest Execution: The tests can be executed locally or integrated into a CI/CD pipeline for automated testing.\nTest Reporting: The feature provides detailed reports, including test results, coverage statistics, and any issues or failures encountered during execution.\nContinuous Integration: The generated tests can be updated or regenerated as the codebase evolves, ensuring they remain aligned with the latest changes and requirements.","how-it-works#How it Works":"Input the source code or directory for which you want to generate unit tests.\nThe Unit Test Generator leverages advanced language models to analyze the code and generate appropriate unit tests in a format compatible with popular testing frameworks.\nThe generator supports multiple programming languages and can handle entire directories of code files.\nYou can find an example here","usage-guide#Usage Guide":"Here's a detailed step-by-step guide on how to use the Unit Test Generator:\nFollow the initial setup guide here.\nCreate a new Python file and import the UnitTestGenerator module from Kaizen package :\nfrom kaizen.generator.unit_test import UnitTestGenerator\ngenerator = UnitTestGenerator()\nProvide the source code file or directory path for which you want to generate unit tests:You can run it for one file at a time:\ngenerator.generate_tests(\n file_path=\"path/to/your/file.py\"\n)\nOr for a directory of files:\ngenerator.generate_tests_from_dir(\n dir_path=\"path/to/your/directory\"\n)\nOptionally, you can configure output path, verbosity, and critique settings.\n...\n output_path=\"path/to/your/directory\",\n enable_critique=True,\n verbose=True,\n max_critique=1\n...\nRun the generator to create unit tests.\ngenerator.run_tests()\nDisplay the test results:\nfor file_path, result in test_results.items():\n    print(f\"Results for {file_path}:\")\n    if \"error\" in result:\n        print(f\"  Error: {result['error']}\")\n    else:\n        print(f\"  Tests run: {result.get('tests_run', 'N/A')}\")\n        print(f\"  Failures: {result.get('failures', 'N/A')}\")\n        print(f\"  Errors: {result.get('errors', 'N/A')}\")\n    print()\nReview and integrate the generated tests into your test suite.","example#Example":"Here's a complete example to generate unit tests for a specific file:\nfrom kaizen.generator.unit_test import UnitTestGenerator\n# Create an instance of the generator\ngenerator = UnitTestGenerator()\n# Generate tests for a specific file\ngenerator.generate_tests(\n    file_path=\"kaizen/helpers/output.py\",\n    enable_critique=True,\n    verbose=True\n)\n# Run the generated tests\ntest_results = generator.run_tests()\n# Display the test results\nfor file_path, result in test_results.items():\n    print(f\"Results for {file_path}:\")\n    if \"error\" in result:\n        print(f\"  Error: {result['error']}\")\n    else:\n        print(f\"  Tests run: {result.get('tests_run', 'N/A')}\")\n        print(f\"  Failures: {result.get('failures', 'N/A')}\")\n        print(f\"  Errors: {result.get('errors', 'N/A')}\")\n    print()","supported-languages#Supported Languages":"Python (.py)\nJavaScript (.js)\nTypeScript (.ts)\nReact (.jsx, .tsx)\nRust (.rs)","benefits#Benefits":"Increased Test Coverage\nTime Efficiency\nConsistency in Testing\nEarly Bug Detection\nSupport for Multiple Programming Languages\nContinuous Improvement through AI Critique","limitations#Limitations":"AI Limitations: May not cover all edge cases or complex scenarios.\nHuman Oversight: Generated tests should be reviewed and potentially modified by developers.\nLanguage Support: Limited to the supported programming languages."}},"/features/work_summary":{"title":"Work Summary","data":{"work-summary-generator#Work Summary Generator":"Create easy-to-understand summaries of code changes for non-technical stakeholders and founders.","key-features#Key Features":"Git Diff Analysis: The feature analyzes Git diffs representing code changes to generate comprehensive summaries.\nNatural Language Summaries: Generates detailed summaries in plain language, making technical changes understandable to non-technical stakeholders.\nSectional Breakdown: Provides a structured summary including high-level overview, feature highlights, and impact analysis.\nSocial Media Integration: Automatically generates Twitter and LinkedIn posts based on the work summary.\nCustomizable Output: Allows customization of summary depth and focus areas based on stakeholder needs.","how-it-works#How it Works":"Provide a Git diff representing the code changes to be summarized.\nThe tool uses advanced language models to analyze the diff and generate a detailed summary.\nThe summary includes a high-level overview, sectional breakdown, plain language explanations, feature highlights, and impact analysis.\nThe tool ensures a consistent, readable structure and can generate social media posts based on the summary.\nYou can find an example here","usage-guide#Usage Guide":"Here's a detailed step-by-step guide on how to use the Work Summary Generator:\nFollow the initial setup guide here.\nCreate a new Python file and import the necessary modules:\nfrom kaizen.reviewer.work_summarizer import WorkSummaryGenerator\nimport requests\nfrom datetime import datetime, timedelta, timezone\nSet up GitHub repository information and date range:\nGITHUB_OWNER = \"YourGitHubUsername\"\nGITHUB_REPO_NAME = \"YourRepoName\"\ncurrent_date = datetime.now(timezone.utc).date()\nsince_date = current_date - timedelta(days=14)\nsince_date_iso = since_date.isoformat()\nFetch commits and generate diff:\n# Fetch commits\ncommits_url = f\"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO_NAME}/commits\"\nparams = {\"since\": since_date_iso}\ncommits_response = requests.get(commits_url, params=params)\ncommits = commits_response.json()\n# Generate diff\nfirst_commit_sha = commits[0][\"sha\"]\nlast_commit_sha = commits[-1][\"sha\"]\ndiff_url = f\"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO_NAME}/compare/{last_commit_sha}...{first_commit_sha}\"\ndiff_response = requests.get(diff_url, headers={\"Accept\": \"application/vnd.github.v3+json\"})\ndiff_data = diff_response.json()\nExtract file diffs:\nfile_diffs = [\n    {\n        \"file\": file_dict[\"filename\"],\n        \"patch\": file_dict[\"patch\"],\n        \"status\": file_dict[\"status\"],\n    }\n    for file_dict in diff_data[\"files\"]\n    if \"patch\" in file_dict\n]\nGenerate work summary and social media posts:\nwork_summary_generator = WorkSummaryGenerator()\nresult = work_summary_generator.generate_work_summaries(file_diffs, user=\"YourUsername\")\nsummary = result[\"summary\"]\ntwitter_post, * = work_summary_generator.generate_twitter_post(summary, user=\"YourUsername\")\nlinkedin_post, * = work_summary_generator.generate_linkedin_post(summary, user=\"YourUsername\")\nDisplay the results:\nprint(f\"Work Summary:\\n{summary}\\n\")\nprint(f\"Twitter Post:\\n{twitter_post}\\n\")\nprint(f\"LinkedIn Post:\\n{linkedin_post}\\n\")\nReview the generated summary and social media posts, and share them with stakeholders as needed.","example#Example":"To try out fast, here's a complete example to generate a work summary from GitHub commits:\nfrom kaizen.reviewer.work_summarizer import WorkSummaryGenerator\nimport requests\nfrom datetime import datetime, timedelta, timezone\n# GitHub repository information\nGITHUB_OWNER = \"Cloud-Code-AI\"\nGITHUB_REPO_NAME = \"kaizen\"\n# Get the current date and calculate the date 14 days ago\ncurrent_date = datetime.now(timezone.utc).date()\nsince_date = current_date - timedelta(days=14)\nsince_date_iso = since_date.isoformat()\n# GitHub API endpoint for getting commits\ncommits_url = f\"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO_NAME}/commits\"\nparams = {\"since\": since_date_iso}\ncommits_response = requests.get(commits_url, params=params)\nif commits_response.status_code != 200:\n    print(\"ERROR: Could not get GitHub commits\")\n    exit(1)\ncommits = commits_response.json()\nfirst_commit_sha = commits[0][\"sha\"]\nlast_commit_sha = commits[-1][\"sha\"]\n# Get the diff between the first and last commits\ndiff_url = f\"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO_NAME}/compare/{last_commit_sha}...{first_commit_sha}\"\ndiff_response = requests.get(diff_url, headers={\"Accept\": \"application/vnd.github.v3+json\"})\ndiff_data = diff_response.json()\n# Extract file diffs\nfile_diffs = [\n    {\n        \"file\": file_dict[\"filename\"],\n        \"patch\": file_dict[\"patch\"],\n        \"status\": file_dict[\"status\"],\n    }\n    for file_dict in diff_data[\"files\"]\n    if \"patch\" in file_dict\n]\n# Generate work summary\nwork_summary_generator = WorkSummaryGenerator()\nresult = work_summary_generator.generate_work_summaries(file_diffs, user=\"oss_example\")\nsummary = result[\"summary\"]\n# Generate social media posts\ntwitter_post, * = work_summary_generator.generate_twitter_post(summary, user=\"oss_example\")\nlinkedin_post, * = work_summary_generator.generate_linkedin_post(summary, user=\"oss_example\")\n# Display results\nprint(f\"Work Summary:\\n{summary}\\n\")\nprint(f\"Twitter Post:\\n{twitter_post}\\n\")\nprint(f\"LinkedIn Post:\\n{linkedin_post}\\n\")","supported-input#Supported Input":"Git diffs\nGitHub repository information","benefits#Benefits":"Bridge the gap between technical and non-technical stakeholders\nKeep stakeholders engaged and informed about development progress\nProvide a user-friendly way for non-technical stakeholders to track development progress\nStreamline the reporting process with automatically generated work summaries\nFacilitate communication across different platforms with integrated social media post generation","limitations#Limitations":"AI Limitations: May not fully capture complex technical nuances or project-specific context.\nGitHub API Limitations: Rate limits and authentication requirements may affect large-scale usage.\nSummary Depth: The level of detail in summaries may vary based on the complexity of code changes."}},"/":{"title":"Index","data":{"welcome-to-kaizen-docs#Welcome to Kaizen Docs":"Kaizen is an open source SDK and Github Bot that aims to simplify QA work using AI. Using Kaizen you can streamline your software quality process by automating code review, test generation, and end-to-end testing, all integrated with your existing code repositories and workflows.","getting-started#Getting Started":"Kaizen Web App\nTo get started quickly, without any setup, checkout this video guide.\nInitial Setup Guide\nTo use Kaizen SDK hosted using pip, follow this guide.\nSelf-Hosting Guide\nTo setup your own instance of Kaizen, follow this guide.","features#Features":"Code Review\nAutomatically get reviews and feedback on code changes in your pull requests on GitHub.\nUnit Tests Generation\nAutomatically create comprehensive unit tests for your code, improving code quality and test coverage.\nCode Scanning\nComprehensive static code analysis to identify potential issues and areas for improvement in your codebase.\nUI Review\nAI-powered analysis and feedback for improving user experience and accessibility of UI components.\nEnd to End Testing\nStreamline E2E testing for web apps using the Playwright testing framework.\nWork Summary Generation\nCreate easy-to-understand summaries of code changes for non-technical stakeholders and founders.","api-reference#API Reference":"API Reference\nExplore the API reference for Kaizen SDK.","contribution-guide#Contribution Guide":"Contribution\nGiven the open-source nature of Kaizen, we welcome contributions from the community.\nFeature Requests\nAlternatively, you can also raise feature requests or bugs in our GitHub repository.","contact-us#Contact Us":"Contact Us\nFor any other inquiries, please contact us here."}},"/initial_setup_guide":{"title":"Initial Setup Guide","data":{"initial-setup-guide#Initial Setup Guide":"This guide will walk you through the initial setup process before trying out Kaizen SDK features.\nCreate and activate a virtual environment:Mac/Linux\npython3 -m venv venv\nsource venv/bin/activate\nWindows\npython -m venv venv\n.\\venv\\Scripts\\activate\nInstall poetry and Kaizen:\npip install poetry kaizen-cloudcode\nNext you might want to configure your models to use your LLMs, tryout the features or self-host Kaizen."}},"/self_hosting_guide":{"title":"Self Hosting Guide","data":{"":"This guide outlines the steps to set up a self-hosted instance of Kaizen, which utilizes a GitHub App to perform various actions related to pull requests (PRs) and repository management.Kaizen allows you to run its API server locally or on your own infrastructure.","prerequisites#Prerequisites":"Before you begin, ensure you have the following prerequisites installed and configured on your system:\nGit: Version control system used to clone the Kaizen repository.\nPython: Required for using Poetry, a dependency manager used by Kaizen.\nDocker and Docker Compose: For deploying and managing containerized applications.\nGitHub Account: You'll need this to set up a GitHub App and configure permissions.","outline#Outline":"To create your own local version of Kaizen, follow along the guide to complete the following steps:\nClone the repository.\nInstall required dependencies.\nCreate a Github app.\nPrepare the configuration settings.\nDeploy the API."}},"/self_hosting_guide/clone_repository":{"title":"Clone Repository","data":{"":"Run the following command in your local machine:\ngit clone https://github.com/cloud-code-ai/kaizen\nThis command will clone the Kaizen repository from GitHub to your local machine."}},"/self_hosting_guide/deploy_api":{"title":"Deploy API","data":{"":"To deploy the Kaizen API using Docker Compose, follow these steps:\nMake sure you have Docker and Docker Compose installed on your system.\nNavigate to the Kaizen project directory:\ncd kaizen\nRun the following command to start the API server and its dependencies using Docker Compose:\ndocker-compose up\nThis command will build and launch the Docker containers defined in the docker-compose.yml file. The API server for Kaizen will be deployed and accessible based on the configurations specified in the docker-compose.yml file.You can monitor the logs and access the API endpoints once the containers are up and running. Use Ctrl + C to stop the Docker Compose process when you're finished."}},"/self_hosting_guide/install_dependencies":{"title":"Install Dependencies","data":{"":"To install dependencies for Kaizen, follow these steps:\nChange directory to the Kaizen project directory:\n   cd kaizen\nUse Poetry to install the project dependencies:\n   poetry install\nThese commands will navigate you into the Kaizen project directory and then use Poetry to install the required dependencies specified in the project's pyproject.toml file.Note: It is reccommended to create a virtual environment before installing modules, so as to manage installation of API specific modules with ease.To set up a virtual environment:Mac/Linux\npython3 -m venv venv\nsource venv/bin/activate\nWindows\npython -m venv venv\n.\\venv\\Scripts\\activate"}},"/self_hosting_guide/prepare_configuration":{"title":"Prepare Configuration","data":{"":"To prepare for deployment, follow these steps to configure the necessary files:\nCopy Environment File:\nCreate a .env file by duplicating .env.example. This file will store environment variables required for the deployment process. Add the values of the key and base you are using based on your LLM.\nSet the Environment Variables Values in your System:\nIn order to use an LLM model's API they environment variables must be defined and saved in the local system for the next step. Open your terminal in the root directory of Kaizen and then do the following:\nMac/Linux\nexport VARIABLE_NAME=\"value\"\nWindows\nsetx VARIABLE_NAME \"value\"\nStore GitHub App PEM File:\nEnsure the PEM file for the GitHub app is stored as GITHUB_APP_KEY.pem within the Kaizen root path. This file is necessary for authentication and interaction with the GitHub platform during deployment.","configuring-features#Configuring Features":"You can adjust additional features by modifying the config.json file. This JSON file controls specific configurations related to the deployment process and application behavior.Note : Make sure to update these files appropriately before proceeding with deployment. Check whether the environment variables are defined properly."}},"/self_hosting_guide/setup_github_app":{"title":"Setup GitHub App","data":{"":"Follow these steps to set up your GitHub app:","registering-your-github-app#Registering Your GitHub App":"Access Developer Settings:\nClick on your profile photo in the upper-right corner of GitHub.\nGo to Settings and then click on Developer settings in the left sidebar.\nCreate a New GitHub App:\nUnder Developer settings, select GitHub Apps and click on New GitHub App.\nProvide App Details:\nEnter the following details for your app:\nGitHub App name: Choose a name for your app.\nHomepage URL: Specify the URL of your app (e.g., repository URL - github.com/[Your GitHub User ID]/kaizen/).\nWebhook URL: Enter the server URL where webhook requests will be sent.\nOptionally, set a Webhook secret for request validation.","configure-webhook-and-permissions#Configure Webhook and Permissions":"Activate Webhook:\nEnsure the \"Webhook\" toggle is set to Active.\nSet Permissions:\nIn the sidebar, navigate to Permissions & events.\nDefine Permissions:\nUnder Repository permissions, Organization permissions, and Account permissions, select required permissions such as:\nRepository Content\nPull Request\nMetadata\nCheck Runs","subscribe-to-events#Subscribe to Events":"Choose Events:\nUnder Subscribe to Events, select the webhook events your app needs to receive (e.g., \"Pull request\" events).\nBy following these steps, your GitHub app will be properly configured with the necessary permissions and event subscriptions for your project."}},"/self_hosting_guide/using_custom_llms_with_kaizen":{"title":"Using Custom Llms with Kaizen","data":{"how-to-integrate-custom-llms-with-kaizen#How to integrate custom LLMs with Kaizen?":"This post addresses how to setup custom LLMs with Kaizen.","step-1-set-environment-variables#Step 1: Set Environment Variables":"First, you need to add the necessary environment variables in your .env file. These variables are essential for authenticating and interacting with the API service of your LLM Provider.\nos.environ[\"LLM_API_KEY\"] = \"<YOUR_LLM_API_KEY>\"  \nos.environ[\"LLM_API_BASE\"] = \"<YOUR_LLM_API_BASE_URL>\"  \nos.environ[\"LLM_API_VERSION\"] = \"<YOUR_LLM_API_VERSION>\"  \nReplace <YOUR_LLM_API_KEY>, <YOUR_LLM_API_BASE_URL>, and <YOUR_LLM_API_VERSION> with your actual LLM's credentials.","step-2-update-configjson#Step 2: Update config.json":"Next, update your config.json file to include the model configuration for LLM.\nKaizen uses litellm under the hood, so your config.json can look something like this.\nThis configuration will specify which model deployment to use and the associated costs per token.\n{\n  \"language_model\": {\n    \"provider\": \"litellm\",\n    \"enable_observability_logging\": false,\n    \"redis_enabled\": false,\n    \"models\": [\n      {\n        \"model_name\": \"default\",\n        \"litellm_params\": {\n          \"model\": \"<MODEL_NAME>/<NAME_OF_DEPLOYMENT>\",\n          \"api_key\": \"os.environ/LLM_API_KEY\",\n          \"api_base\": \"os.environ/LLM_API_BASE\"\n        },\n        \"model_info\": {\n          \"input_cost_per_token\": ...,\n          ...\n        }\n      }\n    ]\n  },\n  \"github_app\": {\n    ...\n  }\n}\nReplace <NAME_OF_DEPLOYMENT> with the name of your LLM model's deployment.\nFor more information on model token pricing, check out here.\nYou can checkout an example hereFeel free to reach out if you have any questions or need further assistance!"}}}